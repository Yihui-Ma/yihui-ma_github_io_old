---
title: 吴恩达——机器学习系列课程 笔记
date: 2019-08-16 15:37:06
tags:
- machine learning
categories:
- machine learning
mathjax: true
---

该笔记为观看视频个人笔记。

## 监督学习
&emsp;&emsp;监督学习算法是指我们给算法一个数据集，其中包含了正确答案，算法的目的就是给出更多的正确答案。

### 分类问题
&emsp;&emsp;分类问题——设法预测一个离散值输出，0或1；有时可能有两种以上的分类。

## 无监督学习
&emsp;&emsp;数据没有任何标签，数据都具有相同的标签或者没有标签。对于给定的数据集，无监督学习算法可能给定该数据包含的两个不同的簇，可以把这些数据分成两个不同的簇，这就是聚类算法；其中一个应用聚类算法的例子是谷歌新闻。无监督学习在其他领域的应用，有如被用来组织大型的计算机集群，管理大型数据中心（大型计算机集群）；用于社交网络的分析；市场细分中的应用，许多公司拥有庞大的客户信息数据库，但预先并不知道有哪些细分市场；用于天文数据分析，这些聚类算法带来了星系形成理论；这些都是聚类，聚类只是无监督学习的一种。 
**鸡尾酒算法**
[W,s,v]=svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');
svd: 是奇异值分解的缩写

## 模型描述
### 线性回归
&emsp;&emsp;回归是指我们预测一个具体的数值输出。另一种最常见的监督学习问题，被称为分类问题，我们用它来预测离散值输出。一元线性回归模型又称为单变量线性回归模型。

## 代价函数
&emsp;&emsp;代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。事实上，求出误差的平方和的原因，在于误差平方代价函数对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段，对于大多数线性回归问题是非常合理的。
&emsp;&emsp;当参数只有一个时，代价函数为二维碗状函数；当参数有两个时，代价函数为三维碗壮函数；